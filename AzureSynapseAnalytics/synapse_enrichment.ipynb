{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Read from Cosmos DB analytical store into a Spark DataFrame and display 10 rows from the DataFrame\n",
        "# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
        "\n",
        "df = spark.read\\\n",
        "    .format(\"cosmos.olap\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDb1\")\\\n",
        "    .option(\"spark.cosmos.container\", \"footprint_analytics\")\\\n",
        "    .load()\n",
        "\n",
        "\n",
        "# take a small sample for demo purpose\n",
        "df_small = df.limit(5)\n",
        "display(df_small)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 35,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.0102249Z",
              "execution_start_time": "2020-12-11T13:32:18.0394485Z",
              "execution_finish_time": "2020-12-11T13:32:30.2498935Z"
            },
            "text/plain": "StatementMeta(geo, 13, 35, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.widget-view+json": {
              "widget_id": "595df37b-d829-46e7-a4bf-1ed0abdd453d",
              "widget_type": "Synapse.DataFrame"
            },
            "text/plain": "SynapseWidget(Synapse.DataFrame, 595df37b-d829-46e7-a4bf-1ed0abdd453d)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {},
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to flatten any struct type column \r\n",
        "\r\n",
        "from pyspark.sql.functions import col\r\n",
        "\r\n",
        "def flatten_df(nested_df):\r\n",
        "    stack = [((), nested_df)]\r\n",
        "    columns = []\r\n",
        "\r\n",
        "    while len(stack) > 0:\r\n",
        "        parents, df = stack.pop()\r\n",
        "\r\n",
        "        flat_cols = [\r\n",
        "            col(\".\".join(parents + (c[0],))).alias(\"_\".join(parents + (c[0],)))\r\n",
        "            for c in df.dtypes\r\n",
        "            if c[1][:6] != \"struct\"\r\n",
        "        ]\r\n",
        "\r\n",
        "        nested_cols = [\r\n",
        "            c[0]\r\n",
        "            for c in df.dtypes\r\n",
        "            if c[1][:6] == \"struct\"\r\n",
        "        ]\r\n",
        "\r\n",
        "        columns.extend(flat_cols)\r\n",
        "\r\n",
        "        for nested_col in nested_cols:\r\n",
        "            projected_df = df.select(nested_col + \".*\")\r\n",
        "            stack.append((parents + (nested_col,), projected_df))\r\n",
        "\r\n",
        "    return nested_df.select(columns)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 36,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.2589519Z",
              "execution_start_time": "2020-12-11T13:32:30.2772127Z",
              "execution_finish_time": "2020-12-11T13:32:32.3111973Z"
            },
            "text/plain": "StatementMeta(geo, 13, 36, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": ""
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the flatt_df, which will work on geometry column\r\n",
        "\r\n",
        "from pyspark.sql.types import StringType, StructField, StructType\r\n",
        "df_flat = flatten_df(df_small)\r\n",
        "display(df_flat)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 37,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.4357138Z",
              "execution_start_time": "2020-12-11T13:32:32.3345818Z",
              "execution_finish_time": "2020-12-11T13:32:34.3560307Z"
            },
            "text/plain": "StatementMeta(geo, 13, 37, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.synapse.widget-view+json": {
              "widget_id": "bd9db473-0888-41fb-a912-63a4b61a420e",
              "widget_type": "Synapse.DataFrame"
            },
            "text/plain": "SynapseWidget(Synapse.DataFrame, bd9db473-0888-41fb-a912-63a4b61a420e)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {},
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create geodataframe - due to aray in aray nesting, some loops are needed\r\n",
        "\r\n",
        "import geopandas as gpd\r\n",
        "from shapely.geometry import shape, Polygon\r\n",
        "import pyspark.sql.functions as F\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "df_geom = pd.DataFrame ([], columns = ['geometry'])\r\n",
        "gdf_geom = gpd.GeoDataFrame(df_geom).set_geometry('geometry')\r\n",
        "\r\n",
        "geom_collection = []\r\n",
        "for x in df_flat.collect():\r\n",
        "    row_id = x['id']\r\n",
        "    geom = x['geometry_coordinates']\r\n",
        "    geom_row = []\r\n",
        "    for i in range(len(geom)):\r\n",
        "        pair = tuple(geom[i][0])\r\n",
        "        geom_row.append(pair)\r\n",
        "    values_to_add = {'geometry': Polygon(geom_row)}\r\n",
        "    row_to_add = pd.Series(values_to_add)\r\n",
        "    gdf_geom = gdf_geom.append(row_to_add, ignore_index=True)\r\n",
        "\r\n",
        "gdf_geom"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 38,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.5347162Z",
              "execution_start_time": "2020-12-11T13:32:34.3828254Z",
              "execution_finish_time": "2020-12-11T13:32:36.415391Z"
            },
            "text/plain": "StatementMeta(geo, 13, 38, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "                                            geometry\n0  POLYGON ((-158.18279 21.43854, -158.18268 21.4...\n1  POLYGON ((-157.99227 21.45864, -157.99218 21.4...\n2  POLYGON ((-157.99392 21.47567, -157.99387 21.4...\n3  POLYGON ((-158.01757 21.50056, -158.01745 21.5...\n4  POLYGON ((-158.02872 21.47663, -158.02872 21.4..."
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set crs to WGS84 = 4326  (in lat long)\r\n",
        "\r\n",
        "gdf_geom = gdf_geom.set_crs(epsg=4326)\r\n",
        "gdf_geom.crs"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 39,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.6372943Z",
              "execution_start_time": "2020-12-11T13:32:36.4381686Z",
              "execution_finish_time": "2020-12-11T13:32:38.4712161Z"
            },
            "text/plain": "StatementMeta(geo, 13, 39, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "<Geographic 2D CRS: EPSG:4326>\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# project to US National Atlas Equal Area (epgs = 2136) - in meter\r\n",
        "\r\n",
        "gdf_geom = gdf_geom.to_crs(epsg=2163)\r\n",
        "gdf_geom.crs"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 40,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.7351705Z",
              "execution_start_time": "2020-12-11T13:32:38.4955118Z",
              "execution_finish_time": "2020-12-11T13:32:40.5243247Z"
            },
            "text/plain": "StatementMeta(geo, 13, 40, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "<Projected CRS: EPSG:2163>\nName: US National Atlas Equal Area\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: United States (USA) - onshore and offshore.\n- bounds: (167.65, 15.56, -65.69, 74.71)\nCoordinate Operation:\n- name: US National Atlas Equal Area\n- method: Lambert Azimuthal Equal Area (Spherical)\nDatum: Not specified (based on Clarke 1866 Authalic Sphere)\n- Ellipsoid: Clarke 1866 Authalic Sphere\n- Prime Meridian: Greenwich"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# derive area for footprints (in meter^2)\r\n",
        "gdf_geom.area"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "geo",
              "session_id": 13,
              "statement_id": 41,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2020-12-11T13:32:18.8366206Z",
              "execution_start_time": "2020-12-11T13:32:40.5486156Z",
              "execution_finish_time": "2020-12-11T13:32:42.5780228Z"
            },
            "text/plain": "StatementMeta(geo, 13, 41, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "0    114.483904\n1    198.073906\n2     86.995961\n3    239.609187\n4    169.204369\ndtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      }
    }
  ],
  "metadata": {
    "sessionOptions": {
      "driverMemory": "56g",
      "driverCores": 8,
      "executorMemory": "56g",
      "executorCores": 8,
      "numExecutors": 2,
      "keepAliveTimeout": 30,
      "conf": {
        "spark.dynamicAllocation.enabled": "false",
        "spark.dynamicAllocation.minExecutors": "2",
        "spark.dynamicAllocation.maxExecutors": "2"
      }
    },
    "saveOutput": true,
    "language_info": {
      "name": "scala",
      "version": "2.11.12",
      "mimetype": "text/x-scala",
      "file_extension": ".scala",
      "pygments_lexer": "scala",
      "codemirror_mode": "scala",
      "nbconvert_exporter": "scala"
    },
    "a365ComputeOptions": {
      "nodeSize": "Medium",
      "auth": {
        "authResource": "https://dev.azuresynapse.net",
        "type": "AAD"
      },
      "name": "geo",
      "nodeCount": 10,
      "endpoint": "https://geosynapse2.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/geo",
      "automaticScaleJobs": false,
      "type": "Spark",
      "id": "/subscriptions/51b37883-3577-465a-b335-cc5c58c3a8c1/resourceGroups/geo-cosmosdb/providers/Microsoft.Synapse/workspaces/geosynapse2/bigDataPools/geo",
      "sparkVersion": "2.4",
      "extraHeader": null
    },
    "microsoft": {
      "language": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}